{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7454fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd547645",
   "metadata": {},
   "source": [
    "### cleaning up the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa70807-a14b-426a-984b-03653172f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date            area  average_price       code  houses_sold  \\\n",
      "0  1995-01-01  city of london          91449  E09000001         17.0   \n",
      "1  1995-02-01  city of london          82203  E09000001          7.0   \n",
      "2  1995-03-01  city of london          79121  E09000001         14.0   \n",
      "3  1995-04-01  city of london          77101  E09000001          7.0   \n",
      "4  1995-05-01  city of london          84409  E09000001         10.0   \n",
      "\n",
      "   no_of_crimes  borough_flag  \n",
      "0           NaN             1  \n",
      "1           NaN             1  \n",
      "2           NaN             1  \n",
      "3           NaN             1  \n",
      "4           NaN             1  \n",
      "        code                  area        date  median_salary  \\\n",
      "0  E09000001        city of london  1999-12-01        33020.0   \n",
      "1  E09000002  barking and dagenham  1999-12-01        21480.0   \n",
      "2  E09000003                barnet  1999-12-01        19568.0   \n",
      "3  E09000004                bexley  1999-12-01        18621.0   \n",
      "4  E09000005                 brent  1999-12-01        18532.0   \n",
      "\n",
      "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
      "0                NaN       48922             0           6581.0   \n",
      "1                NaN       23620             3         162444.0   \n",
      "2                NaN       23128             8         313469.0   \n",
      "3                NaN       21386            18         217458.0   \n",
      "4                NaN       20911             6         260317.0   \n",
      "\n",
      "   number_of_jobs  area_size  no_of_houses  borough_flag  \n",
      "0             NaN        NaN           NaN             1  \n",
      "1             NaN        NaN           NaN             1  \n",
      "2             NaN        NaN           NaN             1  \n",
      "3             NaN        NaN           NaN             1  \n",
      "4             NaN        NaN           NaN             1  \n"
     ]
    }
   ],
   "source": [
    "# read the csv files to Pandas dataframe \n",
    "df_monthly = pd.read_csv('housing_in_london_monthly_variables.csv')\n",
    "df_yearly = pd.read_csv('housing_in_london_yearly_variables.csv')\n",
    "\n",
    "print(df_monthly.head())\n",
    "print(df_yearly.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06c1078-42c8-4fcc-bc5a-00acaf19f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date to Datetime format\n",
    "df_monthly['date'] = pd.to_datetime(df_monthly['date'])\n",
    "df_yearly['date'] = pd.to_datetime(df_yearly['date'])\n",
    "\n",
    "# extract data from 2000 \n",
    "df_monthly = df_monthly[df_monthly['date'].dt.year >= 2000]\n",
    "df_yearly = df_yearly[df_yearly['date'].dt.year >= 2000]\n",
    "\n",
    "# year column for merging two files\n",
    "df_monthly['year'] = df_monthly['date'].dt.year\n",
    "df_yearly['year'] = df_yearly['date'].dt.year\n",
    "\n",
    "# merging two files \n",
    "df_merged = df_monthly.merge(df_yearly, on = ['year', 'area'], how = 'left')\n",
    "df_merged.to_csv('merged_housing_data_2000_latest.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cbb1aa-dd6e-456f-bf3c-b2f8537f921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_x                  0\n",
      "area                    0\n",
      "average_price           0\n",
      "code_x                  0\n",
      "houses_sold            90\n",
      "no_of_crimes         3406\n",
      "borough_flag_x          0\n",
      "year                    0\n",
      "code_y                525\n",
      "date_y                525\n",
      "median_salary         765\n",
      "life_satisfaction    7005\n",
      "mean_salary           525\n",
      "recycling_pct        1497\n",
      "population_size      1041\n",
      "number_of_jobs       1497\n",
      "area_size            2853\n",
      "no_of_houses         2853\n",
      "borough_flag_y        525\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# handling missing values \n",
    "print(df_merged.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe33cd6-6b29-4e29-8da8-875d9fbd15ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_x                0\n",
      "area                  0\n",
      "average_price         0\n",
      "code_x                0\n",
      "houses_sold           0\n",
      "no_of_crimes          0\n",
      "borough_flag_x        0\n",
      "year                  0\n",
      "code_y              525\n",
      "date_y              525\n",
      "median_salary         0\n",
      "mean_salary         705\n",
      "recycling_pct      1497\n",
      "population_size       0\n",
      "number_of_jobs        0\n",
      "area_size             0\n",
      "no_of_houses          0\n",
      "borough_flag_y        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check numeric columns \n",
    "num_cols = df_merged.select_dtypes(include=['number','float64','int64']).columns\n",
    "\n",
    "# filling the missing values with the median of their respective columns \n",
    "df_merged[num_cols] = df_merged[num_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "# dropping this column due to too many missing values\n",
    "if 'life_satisfaction' in df_merged.columns:\n",
    "    df_merged.drop(columns = ['life_satisfaction'], inplace = True)\n",
    "\n",
    "# convert: string values to integer values \n",
    "df_merged['mean_salary'] = pd.to_numeric(df_merged['mean_salary'], errors = 'coerce')\n",
    "df_merged['recycling_pct'] = pd.to_numeric(df_merged['recycling_pct'], errors = 'coerce')\n",
    "\n",
    "print(df_merged.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5f73cf-12ea-4c82-b95a-f878183fd4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns:  Index(['area', 'average_price', 'houses_sold', 'no_of_crimes', 'year',\n",
      "       'median_salary', 'population_size', 'number_of_jobs', 'area_size',\n",
      "       'no_of_houses'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "columns_to_drop = ['code','borough_flag','date_x','code_x', 'borough_flag_x','code_y','date_y','borough_flag_y','mean_salary','recycling_pct']\n",
    "df_merged.drop(columns = [col for col in columns_to_drop if col in df_merged.columns], inplace = True)\n",
    "\n",
    "print(\"Remaining columns: \", df_merged.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85c4dd6-fe45-40e1-b940-68b40f52f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area', 'average_price', 'houses_sold', 'no_of_crimes', 'year',\n",
      "       'median_salary', 'population_size', 'number_of_jobs', 'area_size',\n",
      "       'no_of_houses'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46817444-5a78-463c-8d4a-cb27f0ba4980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             area  average_price  houses_sold  no_of_crimes  year  \\\n",
      "0  city of london         173738         24.0        2132.0  2000   \n",
      "1  city of london         174152         55.0        2132.0  2000   \n",
      "2  city of london         178339         48.0        2132.0  2000   \n",
      "3  city of london         183101         58.0        2132.0  2000   \n",
      "4  city of london         175041         38.0        2132.0  2000   \n",
      "\n",
      "   median_salary  population_size  number_of_jobs  area_size  no_of_houses  \n",
      "0        34903.0           7014.0        361000.0     4323.0      102402.0  \n",
      "1        34903.0           7014.0        361000.0     4323.0      102402.0  \n",
      "2        34903.0           7014.0        361000.0     4323.0      102402.0  \n",
      "3        34903.0           7014.0        361000.0     4323.0      102402.0  \n",
      "4        34903.0           7014.0        361000.0     4323.0      102402.0  \n"
     ]
    }
   ],
   "source": [
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743fe602-3469-4827-bd87-4037fad8ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('merged_housing_data_2000_latest.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0c9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'area' column to numerical values for training the dataset \n",
    "df_cleaned = pd.read_csv('merged_housing_data_2000_latest.csv')\n",
    "df_cleaned['area_encoded'] = df_cleaned['area'].astype('category').cat.codes\n",
    "df_encoded = pd.get_dummies(df_cleaned, columns=['area'], drop_first=True)\n",
    "df_cleaned.to_csv('cleaned_merged_housing_data_2000_latest.csv', index=False)\n",
    "df_encoded = pd.get_dummies(df_cleaned, columns=['area'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952468eb",
   "metadata": {},
   "source": [
    "### Define features and variables for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0be836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['area_encoded', 'houses_sold', 'no_of_crimes', 'year', 'median_salary', \n",
    "            'population_size', 'number_of_jobs', 'area_size', 'no_of_houses']\n",
    "target = 'average_price'\n",
    "\n",
    "# define X (independent variable) and y (dependent variable)\n",
    "X = df_cleaned[features]\n",
    "Y = df_cleaned[target]\n",
    "\n",
    "# split dataset  into training (80%) and testing (20%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0e79c-95c5-4a6b-b1ae-8e4c7b43b512",
   "metadata": {},
   "source": [
    "### Linear Regression & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4742f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Linear Regression', 'MAE': 85895.27727616078, 'MSE': 18605946107.755978, 'R² Score': 0.4647081827471623}\n",
      "{'Model': 'Random Forest Regression', 'MAE': 10070.37700910009, 'MSE': 646947595.4627085, 'R² Score': 0.9813873612211406}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----- linear regression model -----\n",
    "# training\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, Y_train)\n",
    "\n",
    "# prediction\n",
    "lr_prediction_Y = lr_model.predict(X_test)\n",
    "\n",
    "# evaluation\n",
    "lr_metrics = {\n",
    "    \"Model\": \"Linear Regression\",\n",
    "    \"MAE\": mean_absolute_error(Y_test, lr_prediction_Y),\n",
    "    \"MSE\": mean_squared_error(Y_test, lr_prediction_Y),\n",
    "    \"R² Score\": r2_score(Y_test, lr_prediction_Y)\n",
    "}\n",
    "print(lr_metrics)\n",
    "\n",
    "# ----- random forest model -----\n",
    "# training \n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# prediction\n",
    "rf_prediction_Y = rf_model.predict(X_test)\n",
    "\n",
    "# evaluation \n",
    "rf_metrics = {\n",
    "    \"Model\": \"Random Forest Regression\",\n",
    "    \"MAE\": mean_absolute_error(Y_test, rf_prediction_Y),\n",
    "    \"MSE\": mean_squared_error(Y_test, rf_prediction_Y),\n",
    "    \"R² Score\": r2_score(Y_test, rf_prediction_Y)\n",
    "}\n",
    "print(rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c977e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model           MAE           MSE  R² Score\n",
      "0         Linear Regression  85895.277276  1.860595e+10  0.464708\n",
      "1  Random Forest Regression  10070.377009  6.469476e+08  0.981387\n",
      "Predictions saved to predicted_prices.csv\n"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame([lr_metrics, rf_metrics])\n",
    "print(df_metrics)\n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    \"Actual Price\": Y_test.values,\n",
    "    \"Predicted Price (LR)\": lr_prediction_Y,\n",
    "    \"Predicted Price (RF)\": rf_prediction_Y\n",
    "})\n",
    "df_predictions.to_csv(\"predicted_prices.csv\", index=False)\n",
    "print(\"Predictions saved to predicted_prices.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e2eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
